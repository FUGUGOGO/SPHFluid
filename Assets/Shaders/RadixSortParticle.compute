#include "SPHInclude.compute"
#pragma kernel CheckOrder
#pragma kernel CountBucket
#pragma kernel Reorder

#define SORT_SECTION_SIZE 16;
#define SORT_SECTION_SIZE_2D 256;
#define BITS_PER_ROTATION 4
#define BUCKET_SIZE 16

//Input
uint _RotationRound;
StructuredBuffer<Particle> _Particles;

//Update
bool _Ordered;
groupshared uint _GroupBucket[BUCKET_SIZE];
uint _GlobalBucket[BUCKET_SIZE];

//Output
RWStructuredBuffer<Particle> _SortedParticles;

[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void CheckOrder (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;
	if(flatIdx >= _ParticleNum - 1)
		return;
	
	if(_Particle[flatIdx]._cellIdx1d > _Particle[flatIdx]._cellIdx1d + 1)
		InterlockedAnd(_RotationRound, false);
}


[numthreads(SORT_SECTION_SIZE,SORT_SECTION_SIZE,1)]
void CountBucket (uint groupIdx : SV_GroupIndex, uint3 groupId :SV_GroupID)
{
	uint flatIdx = groupIdx + groupId.x * SORT_SECTION_SIZE_2D;
	if(flatIdx >= _ParticleNum)
		return;

	if(groupIdx == 0)
	{
		for(int i = 0; i < BUCKET_SIZE; ++i)
			_GroupBucket[i] = 0;
	}
	GroupMemoryBarrierWithGroupSync();
		
	uint bin = _Particles[bin]._cellIdx1d >> (_RotationRound * BITS_PER_ROTATION) & 15;
	InterlockedAdd(_GroupBucket[bin], 1);

	GroupMemoryBarrierWithGroupSync();

	//compute local prefix sum
	if(groupIdx == 0)
	{
		uint counter = 0;
		for(int i = 0; i < BUCKET_SIZE; ++i)
		{
			uint oldVal = _GroupBucket[i];
			_GroupBucket[i] = counter;s
			counter += oldVal;
		}
	}
	GroupMemoryBarrierWithGroupSync();
	//global prefix sum on CPU (only 16 elements)
}
